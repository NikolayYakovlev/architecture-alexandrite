# 1. Системы и точки логирования
- Shop API: HTTP-запросы, ошибки 5xx, создание `INITIATED`, загрузка файла `FILE_UPLOADED`, переход в `SUBMITTED`, изменение заказа.
- CRM API: HTTP-запросы, ошибки 5xx, смена статусов `MANUFACTURING_APPROVED`, `CLOSED`, и др.
- MES API: HTTP-запросы, ошибки 5xx, смена статусов `PRICE_CALCULATION_STARTED` / `PRICE_CALCULATED`, `MANUFACTURING_*`, `PACKAGING`, `SHIPPED` и др.
    - Модуль расчёта цены внутри MES: этапы, результат, ошибки.
- Фронтенды: ключевые пользовательские действия, ошибки клиентских скриптов.
    - MES Dashboard: первый экран: запрос списка новых заказов.
- RabbitMQ (publish / consume сообщений о смене статуса, ходе расчёта стоимости, DLQ).
- Базы данных (медленные запросы, ошибки соединений).
    - S3: основное структурированное логирование в сервисах (span, JSON‑лог), S3 Server Access Logs для критичных бизнес‑операций (аудит/безопасность).



# 2. Категории логов уровня `INFO`
1. Бизнес события (время жизни заказа):
   - order_id, prev_status, new_status, event_version, source_system, user_id|operator_id|partner_id, timestamp.
2. Инициирование заказа, загрузка файла:
   - order_id, file_name, file_size_bytes, polygon_count и complexity_class (если вычислено), user_id.
3. Запуск, завершение расчёта цены:
   - order_id, complexity_class, polygon_count, started_at, finished_at, duration_ms, outcome (success|timeout|error).
4. Производственные этапы:
   - order_id, stage (`MANUFACTURING_STARTED`|`MANUFACTURING_COMPLETED`|`PACKAGING`|`SHIPPED`), operator_id, prev_stage_latency_seconds.
5. Публикация сообщения в очередь:
   - order_id, message_type, routing_key, queue, trace_id, message_id, attempt, size_bytes.
6. Забор сообщения:
   - order_id, queue, message_id, latency_publish_to_consume_ms, processed (success|retry|dead-letter).
7. Помещение в DLQ:
   - order_id, original_queue, message_type, failure_reason (short code).
8. Dashboard MES (первый экран):
   - query_id, operator_id, filter_params (статус, page), result_count, duration_ms, cache_hit (bool), db_calls.
9. Ошибка бизнес-валидации (если не исключительная):
   - order_id, validation_code, field(s).
10. Успешная аутентификация партнёрского API:
    - partner_id, endpoint_group, rate_quota_remaining.
11. Ключевые действия на фронтендах:
    - user_id/partner_id, action (submit_order|upload_model|open_dashboard), duration_ms (client), trace_id.
12. Промежуточные этапы расчёта цены (MES):
    - order_id, phase_name (mesh_parse|support_calc|price_formula), phase_duration_ms.


## 2.1 Обязательные кореляционные поля:
- timestamp
- trace_id (если реализован трейсинг)
- span_id (опционально)
- order_id (если применим)
- event_version (смена статусов заказ)
- user_id | operator_id | partner_id (минимум один)
- service (shop|crm|mes)
- environment (dev|release|prod)
- request_id (HTTP уровень)
- queue / message_id (для RabbitMQ событий)


## 2.2 Дополнительные уровни
- `WARN`: ретраи, деградация производительности (приближение к threshold), медленный запрос (выше threshold).
- `ERROR`: необработанное исключение, провал в истории статуса заказа, отказ записи в БД, потеря консистентности (конфликты версий).
- `DEBUG` (отключено в проде): включение по feature flag в проблемных модулях (расчёт цены/дашборд).
- `SECURITY` (категория в `INFO`): отказ аутентификации, логин, попытка доступа без прав, аномальная партнёрская активность (количество, размеры запросов).



# 3. Мотивация
> Проблемы «Александрит»:
> - «пропажа» заказов,
> - зависания между статусами,
> - долгое вычисление стоимости изготовления изделия (2–30 мин),
> - потеря партнёрских заказов,
> - жалобы операторов на долгую загрузку списка новых заказов в дашборде MES.
> Всё это заставляет команду тратить много времени на выяснение того, где и почему «застрял» заказ.

Цели логирования:
- фиксация бизнес‑событий (статус заказа, расчёт цены, производство) для быстрой установки факта и причины инцидента,
- корреляция с трейсами и метриками: логи дают полноту (все события), трейсинг — выборку по семплированным операциям,
- снижение времени решения инцидентов и нагрузки поддержки; структурированные записи позволяют фильтровать записи по отдельным атрибутам (order_id, event_version и др.),
- аудит заказов, включая партнёрские (доказуемость SLA: время переходов статусов, длительность расчёта).
- выявление паттернов деградации (массовые ретраи, всплески DLQ) раньше бизнес‑жалоб.


## 3.1 Влияние на технические метрики
- MTTI (Mean Time To Identify): сокращение за счёт прямого поиска, фильтрация по order_id даёт всю цепочку событий.
- MTTR (Mean Time To Repair): быстрее воспроизведение условий ошибки
- Процент инцидентов с установлением причины за первые 30 мин с момента появления.
- Определение доли ошибок, сообщений в DLQ, повторных попыток выполнения команд (Error & retry ratio).
- Определение p95 для `dashboard_first_page_latency` (время загрузки первой страницы дашборда MES).


## 3.2 Влияние на бизнес‑метрики
- Доля «пропавших» заказов (orders_with_status_gap / total_orders).
- Rollback rate релизов (причина деградации фиксируется по логам).
- Время обработки тикета поддержкой (avg support_ticket_resolution_time).
- Операторская продуктивность (orders_started_per_operator_hour — корректность распределения благодаря прозрачности событий).


## 3.3 Приоритет внедрения
Первая очередь (критические бизнес-цепочки, места потерь сообщений):
1. RabbitMQ publish/consume, DLQ (order_id, message_type, queue, retry_count) — установление источника “пропажи” событий.
2. Расчёт цены в MES: start/complete расчёта (order_id, complexity, duration).
3. Статусные переходы (Shop API, MES, CRM) — формирование непрерывного журнала смены статусов заказа.
4. Первый запрос на дашборде MES — жалобы операторов, влияет на их оплату и мотивацию.
5. Партнёрский API (входящие заказы, partner_id) — риск потери контрактов.

### 3.3.1 Параллельное подключение трейсинга (в первую очередь)
Необходим для глубины анализа инцидентов:
- Модуль расчётов: запуск/завершение/результат (без детализации внутренних шагов).
- Медленные DB запросы — ускорение оптимизации.

### 3.3.2 Параллельное подключение трейсинга (продолжение)
- Полная детализация этапов расчета цены.
- Расширенные операторские действия (PACKAGING детализация).
- S3 серверные логи (только для аудита критичных моделей).
- Расширенные SECURITY события (аномальный RPS, паттерны доступа).

### 3.3.3 Приоритет трейсинг vs логирование:
Обобщённое сравнение:
- Трейсинг даёт визуализацию пути (стека вызовов кода распределённых систем) и задержек. Использование авто-инструментации просто во внедрении, но отдельные спаны и пропагация контекста требуют ручного кода аналогично качественному структурированному логированию.
- Логирование даёт полный контекст вызова (поля, частично payload), позволяя воспроизвести и найти причину инцидента (ретроспектива и комплаенс). Оно является необходимм для повышения скорости расследования инцидентов.

Поэтому предпочтительна следующая очерёдность внедрения:
- Для решения проблем с заказами (смена статусов, потери сообщений) в первую очередь необходимо логирование, затем трейсинг (корреляция задержек).
- Для длительной операции расчёта цены трейсинг внедряется первым (визуализация активности); лог фиксирует факт начала/завершения и результат.

Иными словами, логирование необходимо для решения инцидентов, поэтому внедряется в первую очередь. А трейсинг важен/удобен для оптимизации и наглядности (глубина и аудит), потому его стоит внедрять после решения основных проблем бизнеса, вызванных непредсказуемостью и медлительностью системы (пропажи статусов, задержки расчёта, производительность дашбора MES).



# 4. Предлагаемое решение
Файл диаграммы контейнеров: [jewerly_c4_model (original fixed, OTel).drawio](<../Task3/jewerly_c4_model (original fixed, OTel).drawio>)

> ⚠️ _Для упрощения работы с диаграммой, для всех заданий используется единственный drawio-файл_

Страница `OTel (Task4)` (компоненты для автоматического мониторинга выделены оранжевым цветом)

- Системы Shop API, CRM API, MES API, модуль расчёта, RabbitMQ exporters пишут структурированный JSON-лог в `stdout`.
- Со стороны OTel:
    - настраивается чтение JSON-логов из `stdout` (filelog receiver) читает JSON,
    - подключается Loki exporter.
- Фронтенды:
    - Ключевые действия и ошибки JS отправляются на эндпоин `/frontend-log` соответствующих API (Shop, CRM, MES), и логируются обычным образом (общий pipeline).
- RabbitMQ:
    - DLQ / retry события уже логируются приложениями (publish/consume). В будущем можно расширить за счёт серверных логов брокера.
- DB:
    - Логирование критичных и медленных запросов в сервисах, или с помощью собственных механизмов логирования (PostgreSQL, читается тем же filelog receiver).
- S3:
    - Логирование успешных Put/Get ключевых моделей в сервисе. Серверные Access Logs S3 включаются позже (аудит критичных buckets).


## 4.1 Новые / доработанные компоненты (на диаграмме выделены оранжевым цветом)
- OTel Collector (приём OTLP: добавляются логи): добавление log pipeline (filelog receivers, exporters.loki).
- Loki (хранилище логов).
- Grafana: добавление Loki datasource.


## 4.2 Потоки данных
Сервисы (SDK, JSON stdout) → (filelog receiver) OTel Collector (log pipeline) → Loki
Grafana → Loki (query logs)
DevOps / Поддержка → Grafana (просмотр логов и трейсов)


## 4.3. Политика безопасности логов

**Контроль доступа (RBAC)**
Роли:
- devops: полный доступ (все сервисы, все уровни).
- support: фильтрованные логи (INFO/WARN, без DEBUG, без скрытых PII полей).
- dev: доступ ко всем уровням кроме SECURITY.
- partner_readonly: отсутствует (логи не доступны внешним партнёрам).

Grafana:
- Права на Loki datasource по ролям.
- Наружу не экспонируется (только через VPN).

**PII и чувствительные данные**
Запрещено логировать: email, phone, raw 3d модель/бинарные блоки.
Схема:
- На уровне приложения: включён scrubber (не добавлять PII).
- В Collector transform: если у атрибута есть ключ user_email/phone — удаляется.
Обезличивание:
- operator_id → hash (если требуется).
- partner_id допускается (бизнес аудит), но не сочетается с персональными данными.

**Шифрование и транспорт**
- Сервисы пишут в stdout локально, сбор через filelog – сеть не используется, шифрование не требуется
- TLS: сбор в Collector через filelog (внутренняя сеть, шифрование).
- Collector → Loki: HTTPS (внутренняя сеть, шифрование).
- Grafana → Loki: HTTPS (внутренняя сеть, шифрование).

**Аудит и изменения**
- Конфиг Collector логируется версионно (Git).
- Любые изменения правил сбора заносятся в changelog и проходят review.


**Политика хранения**

_Retention_
- Горячие логи (основной поток): 14 дней (оперативное расследование).
- Тёплые (минимальный набор полей: event, timestamp, order_id, trace_id, level): 90 дней (ретроспектива SLA).
- Архив (S3 Glacier / дешёвое хранилище): 180 дней только для SECURITY/аудит (доступ по запросу).
Сжатие: Loki compaction, gzip сегментов.

_Оценка объёма_
- Сред. событий заказа ≈ 15 (статусы, publish/consume, расчёт start/finish).
- 100k заказов / мес → 1.5M строк, также инфраструктурные (x3 ~ 4.5M) ≈ 6M строк.
- Средний JSON ~ 300 bytes → ~1800 MB / месяц сырых. С учётом индекса и реплик ~4-5 GB.

Размер очень зависит от степени покрытия кода логированием, поэтому оценка очень поверхностна.



# 5. Превращение сбора логов в анализ логов
Имеющаяся система сбора логов позволяет автоматизировать их обработку и настроить реакции на их содержимое. Т.е. позволяет не только хранить, но извлекать из них сигналы (например, скорость создания заказов, ошибки, пропуски статусов, производительность) и распространять их по системе и автоматически реагировать.


## 5.1 Алертинг (Loki Ruler / Alertmanager)
Можно использовать Prometheus-совместимые правила поверх LogQL:
- Ошибки всплеск: `count_over_time({service="mes-api",level="ERROR"}[5m]) > 50`
- DLQ аномалия: `rate({event="dlq_put"}[1m]) > 5`
- Отсутствие `PRICE_CALCULATED`: `count_over_time({event="price_calc_completed"}[15m]) == 0 AND count_over_time({event="price_calc_started"}[15m]) > 0`
- Медленные запросы на дашборде: `avg_over_time({event="dashboard_query"} |= "duration_ms=" | unwrap duration_ms [5m]) > 2000`

Далее сигналы отправляются в уже существующий Alertmanager.


## 5.2 Аномалии и всплески
Простой детектор (порог с коэффициентом):
- Внезапный рост новых заказов: `rate({event="order_created"}[1m]) / rate({event="order_created"}[15m]) > 5`
- Партнёрский всплеск: `rate({event="partner_api_call"} |= "partner_id=XYZ"[1m]) > 200`


## 5.3 Производные метрики из логов
Извлекаются с помощью LogQL и отправляются в Prometheus (опционально):
- Error ratio: `(count_over_time(level="ERROR"[5m])) / (count_over_time(level=~"INFO|WARN|ERROR"[5m]))`
- DLQ ratio: `count_over_time(event="dlq_put"[10m]) / count_over_time(event="mq_publish"[10m])`
- Order creation rate: `rate({event="order_created"}[5m])`
Могут быть использованы в дашбордах и SLO.


## 5.4 Безопасность, поиск аномалий
Алерты:
- Частые неудачные логины: `rate({event="auth_failed"}[5m]) > 2`
- Аномальный partner_id: `rate({event="partner_api_call"}[1m]) > partner_quota`
- Всплеск создания заказов: `(sum(rate({event="order_created"}[1m])) / sum(rate({event="order_created"}[15m]))) > 5`
- Подозрительный рост запросов партнёра: `rate(({event="partner_api_call"} |= "partner_id=XYZ")[1m]) > 200`
- Массовый скачок ошибок: `count_over_time({level="ERROR"}[5m]) > 50`
- Аномальное количество DLQ событий: `rate({event="dlq_put"}[1m]) > 5`
- Скачок ретраев сообщений: `rate({event="mq_consume"} |= "result=retry"[5m]) > 30`
- Резкий рост нагрузки на расчёт цены (широкий поток стартов): `rate({event="price_calc_started"}[1m]) / rate({event="price_calc_started"}[15m]) > 4`

\* _Пороговые значения уточняются после базовой калибровки._



# 6. Выбор технологии для работы с логами

| Критерий                          | ELK (Elastic Stack)                              | OpenSearch                | Splunk                                  | Loki                                                    |
|-----------------------------------|--------------------------------------------------|---------------------------|-----------------------------------------|------------------------------------------------------   |
| Лицензия / модель                 | Elastic License (частично нечистый OSS)          | Apache 2.0                | Проприетарная                           | Apache 2.0                                              |
| Стоимость владения                | Высокая: JVM heap, ES кластер, tuning            | Высокая: схоже с ELK      | Очень высокая (лицензия за GB/день)     | Низкая: 1–2 узла + объектное хранилище, лицензия=0      |
| Запросы / язык                    | Kibana + Lucene DSL                              | Kibana/FOS + Lucene DSL   | SPL (мощный, обучаемый)                 | LogQL (PromQL-подобный, прост)                          |
| Масштабирование                   | Требует шардирование + реплики; тяжело при росте | Аналогично Elastic        | Горизонтально, но дорого                | Легко: добавление ingester/querier; экономит storage \* |
| Высокая кардинальность            | Проблемы: рост индекса, heap GC                  | Аналогично                | Лучше, но цена растёт                   | Хорошо: labels ограничить, тело компрессировано \*      |
| Интеграция с OTel                 | Через Beats / OTLP → ES                          | Через Data Prepper / OTLP | Есть OTel apps, но чаще коллектор → HEC | Прямой loki exporter в Collector                        |
| Retention / архив                 | Дорого хранить долго (индекс)                    | Аналогично                | Очень дорого хранить много              | Дешево                                                  |
| Корреляция с метриками / трейсами | Нужно настроить отдельно                         | Аналогично                | Есть App & APM интеграции               | Единый Grafana UI (Prometheus + Tempo + Loki)           |
| Подготовка команды                | Требует ES опыта                                 | Требует ES опыта          | Учить SPL                               | Быстрая (LogQL ≈ PromQL)                                |
| Минусы                            | Ресурсоёмко, сложный тюнинг                      | Аналогично                | Цена                                    | Ограниченные сложные полнотекстовые сценарии \*         |

\* Причина низкой TCO Loki в индексировании только по labels, что занимает меньше ресурсов RAM/CPU; текст хранится в сжатых chunk’ах в object storage; нет тяжёлого reindex/ILM. Это приводит к ограничению полнотекстовых сценариев, но экономит ресурсы системы

### Выбор: Loki

Причины:
- Низкая стоимость хранения и простое масштабирование (нет тяжёлого инвертированного индекса по каждому полю).
- Быстрая интеграция с уже выбранным стеком (Grafana, Prometheus, Tempo, OTel Collector).
- LogQL схож с PromQL, что снижает порог вхождения.
- Использование структурированных логов с ограниченным набором labels соответствует использующейся политике кардинальности.
- Retention 14/90/180 дней реализуется дешевле.